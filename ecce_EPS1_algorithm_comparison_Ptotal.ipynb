{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebcb443-7f91-4452-a416-92e78b119799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "df=pd.read_csv('.\\processed_EPS1.csv',index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fadad2c-7a3c-4a00-9a35-89edbf1160eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetRegressor,TabNetClassifier\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import wget\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee41ca8-6c25-44cd-9f05-014ad579c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(['D2', 'D0', 'Validity', 'ipk', 'irms', 'Vo', 'nZVS'], axis=1)\n",
    "df1 = df1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57425d89-8c79-4b7d-85b2-979b7b33f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ca25f3-4aaa-4c74-b5b9-dfb1333ba448",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Ptotal'\n",
    "\n",
    "df1[\"Set\"] = np.random.choice([\"train\", \"valid\", \"test\"], p =[.8, .1, .1], size=(df1.shape[0],))\n",
    "\n",
    "train_indices = df1[df1.Set==\"train\"].index\n",
    "valid_indices = df1[df1.Set==\"valid\"].index\n",
    "test_indices = df1[df1.Set==\"test\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d815ac-fe09-4f22-95a8-148acee11a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnet_params = { \"optimizer_fn\":torch.optim.Adam,\n",
    "                 \"optimizer_params\":dict(lr=0.1),\n",
    "                 \"scheduler_params\": {\"mode\": 'max', \"factor\": 0.5, \"patience\": 30, \"verbose\": True},\n",
    "                 \"scheduler_fn\":torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                 \"n_d\":32,\n",
    "                 \"n_a\":32,\n",
    "                 #\"n_steps\":5,\n",
    "                 \"n_independent\":5,\n",
    "                 \"n_shared\":5\n",
    "                 \n",
    "                # \"mask_type\":'entmax', # \"sparsemax\"\n",
    "                # \"grouped_features\" : grouped_features\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542dae01-5529-4b57-b17e-e03a9cb4fcae",
   "metadata": {},
   "source": [
    "clf = TabNetRegressor(n_d=12,n_a=12 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7e830d-774b-490b-b61f-20d11922b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_feat = ['Set']\n",
    "features = [ col for col in df1.columns if col not in unused_feat+[target]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e64db-0c97-49d3-8912-4baa7423eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df1[features].values[train_indices]\n",
    "y_train = df1[target].values[train_indices].reshape(-1, 1)\n",
    "\n",
    "X_valid = df1[features].values[valid_indices]\n",
    "y_valid = df1[target].values[valid_indices].reshape(-1, 1)\n",
    "\n",
    "X_test = df1[features].values[test_indices]\n",
    "y_test = df1[target].values[test_indices].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aee288-fd49-4f52-9ce5-08ab3d28f8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 600 if not os.getenv(\"CI\", False) else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b356dc8-81a0-4ca2-97eb-cd41db7e588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['mse'],\n",
    "    max_epochs=max_epochs,\n",
    "    patience=300,\n",
    "    batch_size=1024, virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    #augmentations=aug\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6789c0b-f092-4ae7-a4dc-bc5725e5025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)\n",
    "\n",
    "y_true = y_test\n",
    "\n",
    "test_score = mean_squared_error(y_pred=preds, y_true=y_true)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd9712-2573-46d8-a79e-6211e4116703",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7144c6-ddb0-4dab-a282-ea2d25b56a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importance=clf.feature_importances_.reshape(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c45cbc6-bfaa-4aa1-bc67-91d233a3b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1a37f5-18c7-4e32-8ec9-d42acfe9d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_matrix, masks = clf.explain(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959e1a21-2f2a-4ea9-937f-e16944cc3c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "fig, axs = plt.subplots(1, 1, figsize=(20, 20))\n",
    "axs.imshow(clf.feature_importance)\n",
    "axs.set_title(f\"feature importance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51812a76-9902-4aa8-90a6-ee958e9842a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e6e157-1b04-4179-9fd2-11eec813ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20,20))\n",
    "\n",
    "for i in range(3):\n",
    "    axs[i].imshow(masks[i][1000:1001])\n",
    "    axs[i].set_title(f\"mask {i}\")\n",
    "    axs[i].set_xticklabels(labels = features, rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c410d00f-0772-4edc-bc7f-626b1bc32972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "# 假设你知道列名\n",
    "column_names = ['P', 'Vref', 'D1']\n",
    "temp_X_test = pd.DataFrame(X_test, columns=column_names)\n",
    "print(temp_X_test.columns)\n",
    "\n",
    "explainer = shap.Explainer(clf.predict,X_test)\n",
    "shap_values=explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a748ce0-3deb-407f-91f9-2f914c95ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.feature_names=column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9c4f3-1281-4276-9104-d7368f4479b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1309cf19-7b3a-4545-b0d8-903b74cc05c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.plots.force(shap_values[0],matplotlib=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dae305a-fca9-4f27-aa19-2aa1f55ae8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e53493a-1fe2-46be-a59a-587b7d55abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efc5a02-5117-4241-bdd5-6ef2922658a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('P', shap_values.values,temp_X_test, interaction_index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c189143b-3b0d-4614-ac0c-9d29439c222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('Vref', shap_values.values,temp_X_test, interaction_index='P')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6ccd8b-36c0-4e9c-a000-62c8f3696fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.plots.force(shap_values.base_values[0],shap_values.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f55e7d6-10e7-4172-91b2-da2df0fa621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.base_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb69750d-d617-4ad8-aa14-0e82740278cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "# 定义随机森林模型\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# 定义超参数网格\n",
    "# 定义超参数网格\n",
    "param_grid = {\n",
    "    'n_estimators': [30, 50, 100],\n",
    "    'max_depth': [5, 8, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "\n",
    "# 使用网格搜索进行超参数调优\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 获取最佳模型\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 在测试集上进行预测\n",
    "Ptotal_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# 计算测试集上的MSE和MAE\n",
    "mse_test = mean_squared_error(y_test, Ptotal_test_pred)\n",
    "mape_test = mean_absolute_percentage_error(y_test, Ptotal_test_pred)\n",
    "\n",
    "print(f\"Best Model - MSE on Test Set: {mse_test:.4f} - MAPE on Test Set: {mape_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4666d6ba-4129-45fa-9005-94637c97f822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 定义XGBoost回归模型\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "# 定义超参数网格\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "}\n",
    "\n",
    "# 使用网格搜索进行超参数调优\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 获取最佳模型\n",
    "best_model1 = grid_search.best_estimator_\n",
    "\n",
    "# 在测试集上进行预测\n",
    "Ptotal_test_pred = best_model1.predict(X_test)\n",
    "\n",
    "# 计算测试集上的MSE和MAE\n",
    "mse_test = mean_squared_error(y_test, Ptotal_test_pred)\n",
    "mape_test = mean_absolute_percentage_error(y_test, Ptotal_test_pred)\n",
    "\n",
    "print(f\"Best Model - MSE on Test Set: {mse_test:.4f} - MAPE on Test Set: {mape_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e091683-2d27-4dc2-adfe-7168dce7a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_inputs=MinMaxScaler()\n",
    "scaler_inputs.fit(X_train)\n",
    "inputs_train=scaler_inputs.transform(X_train)\n",
    "inputs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657dd80c-9a9d-4f7f-a039-669e16b8188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_inputs=MinMaxScaler()\n",
    "scaler_inputs.fit(X_valid)\n",
    "inputs_valid=scaler_inputs.transform(X_valid)\n",
    "inputs_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8116055d-b5dd-4935-b8b4-680d36312e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_inputs=MinMaxScaler()\n",
    "scaler_inputs.fit(X_test)\n",
    "inputs_test=scaler_inputs.transform(X_test)\n",
    "inputs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e335d862-cb8c-4263-9f86-ccd6f86cc86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#  定义参数网格\n",
    "\n",
    "# 创建支持向量回归模型\n",
    "model = SVR()\n",
    "\n",
    "# 定义超参数网格\n",
    "param_grid = {\n",
    "    'C': [1,10, 100],\n",
    "    'kernel': ['linear',  'rbf'],\n",
    "}\n",
    "\n",
    "# 使用网格搜索进行超参数调优\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(inputs_train, y_train)\n",
    "\n",
    "# 获取最佳模型\n",
    "best_model1 = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# 输出最佳参数\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "\n",
    "# 在测试集上进行预测\n",
    "Ptotal_test_pred = best_model1.predict(inputs_test)\n",
    "\n",
    "# 计算测试集上的MSE和MAE\n",
    "mse_test = mean_squared_error(y_test, Ptotal_test_pred)\n",
    "mape_test = mean_absolute_percentage_error(y_test, Ptotal_test_pred)\n",
    "\n",
    "print(f\"Best Model - MSE on Test Set: {mse_test:.4f} - MAPE on Test Set: {mape_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8d0c2-0f92-43c4-ac10-07c17b827d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math,copy,time\n",
    "from torch.autograd import Variable\n",
    "class Single_Residual(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,dropout,final=False):\n",
    "        super(Single_Residual,self).__init__()\n",
    "        self.linear_layer=nn.Linear(input_size,hidden_size)\n",
    "        self.final=final\n",
    "        if not self.final:\n",
    "            self.batch_norm=nn.BatchNorm1d(hidden_size)\n",
    "            self.dropout=nn.Dropout(dropout)\n",
    "        self.residual_maker=nn.Parameter(torch.zeros(input_size,hidden_size))\n",
    "        self.residual_maker.requires_grad_(False)\n",
    "        if hidden_size<=input_size:\n",
    "            self.residual_maker[torch.randperm(input_size)[:hidden_size],torch.arange(0,hidden_size)]=1\n",
    "        else:\n",
    "            self.residual_maker[torch.arange(0,input_size),torch.randperm(hidden_size)[:input_size]] = 1\n",
    "            \n",
    "    def forward(self,x):\n",
    "        if self.final:\n",
    "            h1=self.linear_layer(x)\n",
    "        else:\n",
    "            h1=F.relu(self.linear_layer(x))\n",
    "        return h1\n",
    "\n",
    "class Residual_DNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_sizes,dropout):\n",
    "        super(Residual_DNN,self).__init__()\n",
    "        assert isinstance(hidden_sizes,list),'the \"hidden_sizes\" should be list '\n",
    "        hidden_num=len(hidden_sizes)\n",
    "        self.residuals=[f\"self.residual{i}\"for i in range(hidden_num)]\n",
    "        for i in range(hidden_num):\n",
    "            if i==hidden_num-1:\n",
    "                exec(self.residuals[i]+\"=Single_Residual(input_size,hidden_sizes[i],dropout,True)\")\n",
    "            else:\n",
    "                exec(self.residuals[i]+\"=Single_Residual(input_size,hidden_sizes[i],dropout)\")\n",
    "            input_size=hidden_sizes[i]\n",
    "    def forward(self,x):\n",
    "        for residual in self.residuals:\n",
    "            x=eval(residual)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5cc0e7-4ccb-492f-928d-8c1ef1424972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# 数据类型转换\n",
    "inputs_train = torch.tensor(inputs_train).float()\n",
    "y_train = torch.tensor(y_train).float()\n",
    "inputs_valid = torch.tensor(inputs_valid).float()\n",
    "y_valid = torch.tensor(y_valid).float()\n",
    "inputs_test = torch.tensor(inputs_test).float()\n",
    "y_test = torch.tensor(y_test).float()\n",
    "\n",
    "# 创建 DataLoader\n",
    "train_data = TensorDataset(inputs_train, y_train)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=12, shuffle=True)\n",
    "\n",
    "# 定义模型\n",
    "input_size = inputs_train.shape[1]\n",
    "hidden_sizes = [256, 128,64,1]  # 调整隐藏层大小\n",
    "dropout = 0  # 调整丢弃率\n",
    "model = Residual_DNN(input_size, hidden_sizes, dropout)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.08)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=30, factor=0.5, verbose=True)\n",
    "\n",
    "# 训练模型\n",
    "epochs =500\n",
    "best_mse = float('inf')\n",
    "early_stopping_patience = 150\n",
    "best_model_state = None\n",
    "patience = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 评估模型性能\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_pred = model(inputs_valid)\n",
    "        mse = mean_squared_error(y_valid, valid_pred)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Validation MSE: {mse:.4f}\")\n",
    "        \n",
    "        # 学习率调度\n",
    "        scheduler.step(mse)\n",
    "        \n",
    "        # 检查并保存最佳模型\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience > early_stopping_patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "# 加载最佳模型\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "# 在测试集上计算MSE\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(inputs_test)\n",
    "    test_mse = mean_squared_error(y_test, test_pred)\n",
    "    test_mape = mean_absolute_percentage_error(y_test, test_pred)\n",
    "    \n",
    "    print(f\"Test MSE with best model: {test_mse:.4f}\")\n",
    "    print(f\"Test MAPE with best model: {test_mape:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fa5771-1189-492b-8d8a-16a7ed06601a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
