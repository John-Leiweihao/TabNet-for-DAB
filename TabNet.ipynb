{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87034cd6-3e45-4104-9ff6-fe11abf95090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model import create_data,Model_TabNet,Model_NN,Model_prevailing,score\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c9d006-b28f-4a41-98e1-ecc7e5f1dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_valid,y_valid,X_test,y_test=create_data('.\\data.\\processd_EPS1.csv','EPS1','Ptotal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be862dd-ca91-4c66-b382-84a682106b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TabNet=Model_TabNet(X_train, y_train,X_valid, y_valid,'Ptotal',16,16,500,100,1024,256)\n",
    "MSE_Tabnet=score(TabNet,'Ptotal',X_test,y_test)\n",
    "\n",
    "\n",
    "XGBoost,params1=Model_prevailing('XGBoost',X_train,y_train,'Ptotal')\n",
    "MSE_XGBoost=score(XGBoost,'Ptotal',X_test,y_test)\n",
    "\n",
    "\n",
    "RandomForest,params2=Model_prevailing('RandomForest',X_train,y_train,'Ptotal')\n",
    "MSE_RandomForest=score(RandomForest,'Ptotal',X_test,y_test)\n",
    "\n",
    "\n",
    "SVM,params3=Model_prevailing('SVM',X_train,y_train,'Ptotal')\n",
    "MSE_SVM=score(SVM,'Ptotal',X_test,y_test)\n",
    "\n",
    "NN=Model_NN(X_train,y_train,X_valid,y_valid,'Ptotal')\n",
    "MSE_NN=score(NN,'Ptotal',X_test,y_test)\n",
    "\n",
    "X_train1,y_train1,X_valid1,y_valid1,X_test1,y_test1=create_data('.\\\\data.\\\\unprocessed_EPS1.csv','EPS1','Ptotal')\n",
    "\n",
    "TabNet1=Model_TabNet(X_train1, y_train1,X_valid1, y_valid1,'Ptotal',16,16,500,100,1024,256)\n",
    "MSE_Tabnet1=score(TabNet1,'Ptotal',X_test1,y_test1)\n",
    "\n",
    "print(f\"The current value of MSE_Tabnet is{MSE_Tabnet}\")\n",
    "print(f\"The current value of MSE_XGBoost is{MSE_XGBoost}\")\n",
    "print(f\"The current value of MSE_RandomFores is{MSE_RandomForest}\")\n",
    "print(f\"The current value of MSE_SVM is{MSE_SVM}\")\n",
    "print(f\"The current value of MSE_NN is{MSE_NN}\")\n",
    "print(f\"The current value of MSE_Tabnet1 is{MSE_Tabnet1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af72bae-4eab-41e9-a296-59c9c8b835f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Feature Importance Evaluation\n",
    "\n",
    "TabNet.feature_importance=TabNet.feature_importances_.reshape(1,3)\n",
    "explain_matrix, masks = TabNet.explain(X_test)\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(20, 20))\n",
    "axs.imshow(TabNet.feature_importance)\n",
    "axs.set_title(f\"feature importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793c7bbb-2f66-433c-b244-51444275577d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20,20))\n",
    "features = [\"\",\"P\",\"\", \"Vref\",\"\",\"D1\"]\n",
    "for i in range(3):\n",
    "    axs[i].imshow(masks[i][1000:1001])     #Select specific samples for analysis to evaluate the importance of each feature at each decision step.\n",
    "    axs[i].set_title(f\"mask {i}\")\n",
    "    axs[i].set_xticklabels(labels = features, rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355340f8-d6b0-4c56-b004-65728eb0b2f8",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1>    SHAP    </h1>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"image/SHAP.png\" alt=\"SHAP\" width=\"100\"/>\n",
    "</di)>\r\n",
    "\n",
    "Using SHAP (SHapley Additive exPlanations) to perform interpretability analysis on a model built with TabNet allows for an in-depth understanding of the model's decision-making process at both global and individual levels. At the global level, analyzing all samples quantifies the overall contribution of each feature to the prediction outcomes, identifying which features have a positive or negative influence on the predictions. At the individual level, SHAP analysis can quantify the effect of each feature on the prediction for a specific sample, revealing how each feature contributes to the model's output for that instance. This interpretability analysis supports the transparency and reliability of the model, helping to identify potential biases and areas for optimizati\n",
    "\n",
    "For more information, please refer to the [SHAP Official Documentation](https://shap.readthedocs.io/en/latest/index.html).on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c22ced-c21a-4f45-8c9f-2afbe6e006fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "column_names = ['P', 'Vref', 'D1']\n",
    "temp_X_test = pd.DataFrame(X_test, columns=column_names)\n",
    "explainer = shap.Explainer(TabNet.predict,X_test)\n",
    "shap_values=explainer(X_test)\n",
    "shap_values.feature_names=column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9690a1-aa5d-4ad6-8e3e-42cca58b116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb83e336-e2d3-4e90-b8fd-31c52468575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.plots.force(shap_values[0],matplotlib=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df08d6b-b560-41f1-9576-e8be13f9d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65734a-4fe7-47fa-bd99-a73f289f3614",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45980a02-403f-406d-baa1-8d45bea2bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('P', shap_values.values,temp_X_test, interaction_index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501ac2f3-154f-4229-9a7d-475005df7b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.plots.force(shap_values.base_values[0],shap_values.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a417939b-3ea1-48da-ab4e-709832e6ad27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
