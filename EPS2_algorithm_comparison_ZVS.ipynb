{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7183bcc4-affa-40fb-af65-0ca70af3b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "#Load data\n",
    "df=pd.read_csv('.\\data.\\processed_EPS1.csv',index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4563b1f-006f-4cd8-9732-f26d0e7e0b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetRegressor,TabNetClassifier\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "import os\n",
    "import wget\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c630ffe2-e5c5-4d42-8826-3fe485deadf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(['D1', 'D0', 'Validity', 'ipk', 'irms', 'Vo', 'Ptotal'], axis=1)\n",
    "df2 = df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f51f4e-b205-437b-9ac6-b750c14138c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0aca7c-8f13-4b09-b05b-f56ead920fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'nZVS'\n",
    "#Divide the dataset into training set, validation set and test set\n",
    "if \"Set\" not in df2.columns:\n",
    "    df2[\"Set\"] = np.random.choice([\"train\", \"valid\", \"test\"], p =[.8, .1, .1], size=(df2.shape[0],))\n",
    "train_indices = df2[df2.Set==\"train\"].index\n",
    "valid_indices = df2[df2.Set==\"valid\"].index\n",
    "test_indices = df2[df2.Set==\"test\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2cb8c0-bbbb-4b86-9ba5-7fd9f5216c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnet_params = { \"optimizer_fn\":torch.optim.Adam,\n",
    "                 \"optimizer_params\":dict(lr=0.02),\n",
    "                 \"scheduler_params\": {\"mode\": 'max', \"factor\": 0.5, \"patience\": 30, \"verbose\": True},\n",
    "                 \"scheduler_fn\":torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                 \"n_d\":32,\n",
    "                 \"n_a\":32,\n",
    "                 \"n_steps\":5,\n",
    "                 \"n_independent\": 5,\n",
    "                # \"mask_type\":'entmax', # \"sparsemax\"\n",
    "                # \"grouped_features\" : grouped_features\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d60bcb-aa62-4d89-b17f-823df03b62f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = TabNetClassifier(n_d=16,n_a=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343bee73-f57b-4e64-9bb9-84d16fa801cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_feat1 = ['Set']\n",
    "features1 = [ col for col in df2.columns if col not in unused_feat1+[target]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713a0ba7-b4bd-4f9b-8304-8fe817f881ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df2[features1].values[train_indices]\n",
    "y_train = df2[target].values[train_indices]\n",
    "\n",
    "X_valid = df2[features1].values[valid_indices]\n",
    "y_valid = df2[target].values[valid_indices]\n",
    "\n",
    "X_test = df2[features1].values[test_indices]\n",
    "y_test = df2[target].values[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea507a2-71d7-4d7e-b211-f77ea2c62f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d793bee2-a3d7-4a73-8faf-bc2030f255a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nZVS_train=(y_train-4)/2\n",
    "nZVS_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bddbb6d-32dc-4599-9f26-472dd5f387a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nZVS_valid=(y_valid-4)/2\n",
    "nZVS_test=(y_test-4)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6d2a3a-5848-4df2-83cd-f7530aa7d007",
   "metadata": {},
   "outputs": [],
   "source": [
    "nZVS_train1=torch.tensor(nZVS_train)\n",
    "nZVS_valid1=torch.tensor(nZVS_valid)\n",
    "nZVS_test1=torch.tensor(nZVS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe21de-8119-40e1-816b-d17b0d098659",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 600 if not os.getenv(\"CI\", False) else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bb14d9-d32d-4114-b668-7f7d18b47b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(\n",
    "    X_train=X_train, y_train=nZVS_train,\n",
    "    eval_set=[(X_train, nZVS_train), (X_valid, nZVS_valid)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['accuracy'],\n",
    "    max_epochs=max_epochs,\n",
    "    patience=200,\n",
    "    batch_size=1024, virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    #augmentations=aug\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ac7921-1254-4927-97c5-276c10f67067",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)\n",
    "\n",
    "y_true = nZVS_test\n",
    "\n",
    "test_score = accuracy_score(y_pred=preds, y_true=y_true)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c9a8d0-ed09-4216-a258-55c93114c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the Random Forest Model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Define the Hyperparameter Grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning with grid searc\n",
    "grid = GridSearchCV(rf_model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid.fit(X_train, nZVS_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Prediction on the test set\n",
    "nZVS_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the MSE and MAE on the test set\n",
    "accuracy = accuracy_score(nZVS_test, nZVS_test_pred)\n",
    "report = classification_report(nZVS_test, nZVS_test_pred)\n",
    "\n",
    "print(f\"Best Parameters: {grid.best_params_}\")\n",
    "print(f\"Accuracy on Test Set: {accuracy:.4f}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f366e51-2095-4f67-afd2-fc1e1d3a1a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the XGBoost Model\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50,100,200],  \n",
    "    'max_depth': [4, 5,6],  \n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X_train, nZVS_train)\n",
    "\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "\n",
    "nZVS_test_pred = best_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(nZVS_test, nZVS_test_pred)\n",
    "print(f\"Accuracy on Test Set: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d2b9c-f097-4129-a8f7-eaca42fa1b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_inputs=MinMaxScaler()\n",
    "scaler_inputs.fit(inputs_train)\n",
    "inputs_train=scaler_inputs.transform(inputs_train)\n",
    "inputs_train=torch.tensor(inputs_train)\n",
    "inputs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9772592f-ac7e-4559-bb1e-226229041d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_inputs=MinMaxScaler()\n",
    "scaler_inputs.fit(inputs_valid)\n",
    "inputs_valid=scaler_inputs.transform(inputs_valid)\n",
    "inputs_valid=torch.tensor(inputs_valid)\n",
    "inputs_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee2526-41a3-4b34-848c-05cab17632a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_inputs=MinMaxScaler()\n",
    "scaler_inputs.fit(inputs_test)\n",
    "inputs_test=scaler_inputs.transform(inputs_test)\n",
    "inputs_test=torch.tensor(inputs_test)\n",
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec1c74d-2713-4a61-9b81-68294c6a0caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Define the SVR Model\n",
    "model = SVC()\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'C': [1,10, 100],\n",
    "    'kernel': ['linear',  'rbf'],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(inputs_train, nZVS_train)\n",
    "\n",
    "\n",
    "best_model1 = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "\n",
    "\n",
    "nZVS_test_pred = best_model1.predict(inputs_test)\n",
    "\n",
    "accuracy = accuracy_score(nZVS_test, nZVS_test_pred)\n",
    "report = classification_report(nZVS_test, nZVS_test_pred)\n",
    "\n",
    "\n",
    "print(f\"Accuracy on Test Set: {accuracy:.4f}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727d9edc-c525-4ccf-a049-fe0aac4fb7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132e43e5-d214-415f-9d44-8d81c3a8bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "nZVS_train1=torch.tensor(nZVS_train)\n",
    "nZVS_valid1=torch.tensor(nZVS_valid)\n",
    "nZVS_test1=torch.tensor(nZVS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f159365-b20e-4518-907d-425c0066860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(inputs_train,nZVS_train1)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "valid_dataset = TensorDataset(inputs_valid,nZVS_valid1)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1024, shuffle=True)\n",
    "test_dataset = TensorDataset(inputs_test,nZVS_test1)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af76847-eaed-4f0d-8b3a-9a98974685ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math,copy,time\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde9c37-b16c-43db-8801-933b76f9e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Single_Residual1(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,dropout,final=False):\n",
    "        super(Single_Residual1,self).__init__()\n",
    "        self.linear_layer=nn.Linear(input_size,hidden_size)\n",
    "        self.final=final\n",
    "        if not self.final:\n",
    "            self.batch_norm=nn.BatchNorm1d(hidden_size)\n",
    "            self.dropout=nn.Dropout(dropout)\n",
    "        self.residual_maker=nn.Parameter(torch.zeros(input_size,hidden_size))\n",
    "        self.residual_maker.requires_grad_(False)\n",
    "        if hidden_size<=input_size:\n",
    "            self.residual_maker[torch.randperm(input_size)[:hidden_size],torch.arange(0,hidden_size)]=1\n",
    "        else:\n",
    "            self.residual_maker[torch.arange(0,input_size),torch.randperm(hidden_size)[:input_size]] = 1\n",
    "            \n",
    "    def forward(self,x):\n",
    "        if self.final:\n",
    "            h1=self.linear_layer(x)\n",
    "        else:\n",
    "            h1=F.relu(self.linear_layer(x))\n",
    "        return h1\n",
    "\n",
    "class Residual_DNN1(nn.Module):\n",
    "    def __init__(self,input_size,hidden_sizes,dropout,num_classes):\n",
    "        super(Residual_DNN1,self).__init__()\n",
    "        assert isinstance(hidden_sizes,list),'the \"hidden_sizes\" should be list '\n",
    "        hidden_num=len(hidden_sizes)\n",
    "        self.residuals=[f\"self.residual{i}\"for i in range(hidden_num)]\n",
    "        for i in range(hidden_num):\n",
    "            if i==hidden_num-1:\n",
    "                exec(self.residuals[i]+\"=Single_Residual1(input_size,hidden_sizes[i],dropout,True)\")\n",
    "            else:\n",
    "                exec(self.residuals[i]+\"=Single_Residual1(input_size,hidden_sizes[i],dropout)\")\n",
    "            input_size=hidden_sizes[i]\n",
    "        self.output_layer = nn.Linear(input_size, num_classes)\n",
    "    def forward(self,x):\n",
    "        for residual in self.residuals:\n",
    "            x=eval(residual)(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b2fa32-bbff-48e5-8d1c-afbb70a80d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Initialize model\n",
    "input_size = 3\n",
    "hidden_sizes = [64, 128, 256, 3]\n",
    "dropout = 0.1\n",
    "num_classes = 3\n",
    "model = Residual_DNN1(input_size, hidden_sizes, dropout, num_classes)\n",
    "model.train()\n",
    "epochs = 200\n",
    "\n",
    "# Define the loss function and optimiser\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=15, verbose=True)\n",
    "\n",
    "# Model training\n",
    "best_accuracy = 0.0\n",
    "best_model_state = None\n",
    "early_stopping_patience = 80\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs = inputs.float()\n",
    "        targets = targets.squeeze().long()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate model performance\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in valid_loader:  \n",
    "            inputs = inputs.float()\n",
    "            targets = targets.squeeze().long()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_predictions.extend(predicted.numpy())\n",
    "            all_targets.extend(targets.numpy())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    print(f'Epoch {epoch}: Validation Accuracy = {accuracy}')\n",
    "    scheduler.step(accuracy)\n",
    "\n",
    "    # Check and save the best model\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model_state = model.state_dict()\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    \n",
    "    if epochs_no_improve == early_stopping_patience:\n",
    "        print(f'Early stopping triggered after {epoch + 1} epochs.')\n",
    "        break\n",
    "\n",
    "# load the best model\n",
    "model.load_state_dict(best_model_state)\n",
    "model.eval()\n",
    "\n",
    "#Calculate the MSE and MAE on the test set\n",
    "all_test_predictions = []\n",
    "all_test_targets = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.float()\n",
    "        targets = targets.squeeze().long()\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_test_predictions.extend(predicted.numpy())\n",
    "        all_test_targets.extend(targets.numpy())\n",
    "\n",
    "test_accuracy = accuracy_score(all_test_targets, all_test_predictions)\n",
    "print(f'Test Accuracy with best model: {test_accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b6435-1285-48df-85e9-4619c0a293c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
